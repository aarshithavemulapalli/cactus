{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Large Language Model Agents in LangChain\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZvdvnD8EzvI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a brief introduction for how to use `LangChain` for the building of Large Language Model agents.\n",
        "\n",
        "LLM-Agents are essentially LLMs that are given tools specific to their desired task. This means that if you want an LLM to be able to configure a database, or access the internet, Agents are how you go about this task.\n",
        "\n",
        "This tutorial will step you through a potential application of LLMs - an SQL Database manager. We will see how to load in a local LLM through `vllm` as well as use an API-based model such as gpt-4, gemini-pro, or claude.\n",
        "\n",
        "This tutorial is adapted from a tutorial build by PineCone-IO at https://github.com/pinecone-io/examples"
      ],
      "metadata": {
        "id": "I0YFm2BlrzsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "AFllW25VtZJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start, let's install the packages we will be using for this example."
      ],
      "metadata": {
        "id": "z3pQ_JugtbMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU torch==2.3.0 vllm==0.4.2 kaleido python-multipart typing-extensions langchain langchain_community langchain_core openai google-search-results wikipedia sqlalchemy langchain_openai"
      ],
      "metadata": {
        "id": "5mIAiKk45l1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SQL Agent - Setup\n",
        "\n",
        "Pretend we have an SQL database that we would like to set up an LLM to interact with. This type of integration can provide a natural language way of gaining insights from your database. This can assist non-experts in utilizing your groups data to form insights.\n",
        "\n",
        "We will first need to create an SQL database, then set up an LLM to interface with the database.\n",
        "\n",
        "⚠️ In this tutorial we will try and use local Google Colab GPU resources, but the free tier of colab prohibits larger models and may decrease the reliability of the LLM-Agents. For this situation, we will provide an additional loader for the OpenAI API models, but you will need an API-key to utilize this resoruce. ⚠️"
      ],
      "metadata": {
        "id": "h3VcwICxtf__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Database"
      ],
      "metadata": {
        "id": "C3f1JjeJvxX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import MetaData\n",
        "\n",
        "metadata_obj = MetaData()\n",
        "\n",
        "## Build the MetaData container object that keeps together many different features of a database (or multiple databases) being described."
      ],
      "metadata": {
        "id": "9a8AxybY8VJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import Column, Integer, String, Table, Date, Float\n",
        "\n",
        "observations = Table(\n",
        "    \"observations\",\n",
        "    metadata_obj,\n",
        "    Column(\"obs_id\", Integer, primary_key=True),\n",
        "    Column(\"sensor_id\", String(10), nullable=False),  # Identifier for the sensor\n",
        "    Column(\"measurement\", Float, nullable=False),   # Scientific measurement (e.g., temperature, pressure, etc.)\n",
        "    Column(\"date\", Date, nullable=False),\n",
        "    Column(\"location\", String(50)),                   # Where the measurement was taken\n",
        ")\n",
        "\n",
        "## Represent a table in a database."
      ],
      "metadata": {
        "id": "SUZQOJpF5YNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These above 2 cells build the skeleton of our database. We can see from the names that we are constructing a scientific measurement database that contains sensors collecting unique information on a certain date and time."
      ],
      "metadata": {
        "id": "zue92O-TvF77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine(\"sqlite:///:memory:\")\n",
        "metadata_obj.create_all(engine)"
      ],
      "metadata": {
        "id": "ei-vVamk5XV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "data = [\n",
        "    [1, 'TEMP001', 25.5, datetime(2023, 6, 1), 'Lab A'],\n",
        "    [2, 'TEMP001', 24.8, datetime(2023, 6, 2), 'Lab A'],\n",
        "    [3, 'PRESS002', 1013.2, datetime(2023, 6, 1), 'Field Site X'],\n",
        "    [4, 'PRESS002', 1012.8, datetime(2023, 6, 2), 'Field Site X'],\n",
        "    [5, 'HUMID003', 55.0, datetime(2023, 6, 1), 'Greenhouse 1'],\n",
        "    [6, 'HUMID003', 60.2, datetime(2023, 6, 2), 'Greenhouse 1'],\n",
        "]"
      ],
      "metadata": {
        "id": "qtaxckSi5QIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import insert\n",
        "\n",
        "def insert_observation(obs):\n",
        "    \"\"\"Inserts a single scientific observation into the database.\"\"\"\n",
        "\n",
        "    stmt = insert(observations).values(\n",
        "        obs_id=obs[0],\n",
        "        sensor_id=obs[1],\n",
        "        measurement=obs[2],\n",
        "        date=obs[3],\n",
        "        location=obs[4]  # Added to insert location data\n",
        "    )\n",
        "\n",
        "    with engine.begin() as conn:\n",
        "        conn.execute(stmt)\n",
        "\n",
        "# Example usage (assuming you have your 'engine' and 'data' from before):\n",
        "for obs in data:\n",
        "    insert_observation(obs)"
      ],
      "metadata": {
        "id": "SffyHr398X-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These above 3 cells have created our locally hosted SQL-Database along with filled out some sample information pertaining to the skeleton we previously created."
      ],
      "metadata": {
        "id": "VzyFiAXNvqb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "rxuTdsmpvs9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Large Language Models\n",
        "\n",
        "Now that we have a toy database constructed and running in our notebook, it is time to create our LLM agent. We will first provide instructions for spinning up a `vllm`-based LLM which pulls in models from `HuggingFace`. Then we will show the equivalent steps for OpenAI."
      ],
      "metadata": {
        "id": "neL_6s7Svuac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain.chains import create_sql_query_chain\n",
        "from langchain_community.llms import VLLM\n",
        "\n",
        "local_llm = VLLM(\n",
        "    model=\"microsoft/Phi-3-mini-4k-instruct\", # Set some HF model name, we prefer smaller models since they have to fit in 15 GB of vram\n",
        "    trust_remote_code=True,  # mandatory for hf models\n",
        "    temperature=0,\n",
        "    dtype=\"float16\", # This is only required when using the T4 GPU on Colab\n",
        ")\n",
        "\n",
        "db = SQLDatabase(engine) # Add the SQL database into memory\n",
        "sql_chain = create_sql_query_chain(llm, db) # Combine the loaded LLM with the SQL Database to form an LLM Chain (Not an agent)\n",
        "\n",
        "# Test the chain, this chain has no thought process, it will just try and convert your question into an SQL Query\n",
        "sql_chain.invoke({\"question\": \"How many employees are there\"})"
      ],
      "metadata": {
        "id": "JcPK5GERAJiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain.chains import create_sql_query_chain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0) # You need to have you OPENAI_API Key set. If not add OPENAI_API_KEY to the secrets tab on the left side of the screen (click the key)\n",
        "db = SQLDatabase(engine) # Add the SQL database into memory\n",
        "sql_chain = create_sql_query_chain(llm, db)  # Combine the loaded LLM with the SQL Database to form an LLM Chain (Not yet an agent)\n"
      ],
      "metadata": {
        "id": "fD0nkAv7xATp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "ZbGS3TPtyDk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Agent\n",
        "\n",
        "Now that we have our `local_llm` or `openai_llm` formed into an sql_query_chain, we can add that chain to an `AgentExecutor` type which will provide the background thought process that the agent should be able to handle.\n",
        "\n",
        "There are a few different pre-made Agent types that LangChain provides:\n",
        "\n",
        "1. Zero Shot React\n",
        "2. Conversational React\n",
        "3. React Docstore\n",
        "\n",
        "or variations of these, which can be found in the documentation [here](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_types.AgentType.html)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "We are going to use the Zero Shot React agent type. This type of agent is used to perform 'zero shot' tasks on the input. That means that we will not have several, interdependent interactions but only one. In other words, this agent will have no memory."
      ],
      "metadata": {
        "id": "Bc0dRUB2yE4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.agents.agent_types import AgentType\n",
        "\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=SQLDatabaseToolkit(db=db, llm=llm), # Add the database and LLM\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    max_iterations=3,\n",
        "    handle_parsing_errors=True,\n",
        ")"
      ],
      "metadata": {
        "id": "5Wd11tgZCYk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.run(\"How many entries contain TEMP001?\")"
      ],
      "metadata": {
        "id": "MmKF2VFc-5On"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}